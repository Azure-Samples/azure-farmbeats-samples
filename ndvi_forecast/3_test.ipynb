{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "\n",
    "Licensed under the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NDVI Forecast on Area of Interest (AOI)\n",
    "This notebook demonstrates, how to load the model which has been trained using previous notebook, [2_train.ipynb](./2_train.ipynb) and forecast NDVI for next 10 days on new Area of Interest.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stanadard library imports\n",
    "import json\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "import sys\n",
    "import requests\n",
    "from datetime import datetime,timedelta\n",
    "\n",
    "# Disable unnecessary logs \n",
    "import logging\n",
    "logging.disable(sys.maxsize)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Third party library imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Local imports\n",
    "from utils.ard_util import ard_preprocess\n",
    "from utils.config import farmbeats_config\n",
    "from utils.constants import CONSTANTS\n",
    "from utils.satellite_util import SatelliteUtil\n",
    "from utils.test_helper import get_sat_weather_data, get_timezone\n",
    "from utils.weather_util import WeatherUtil\n",
    "\n",
    "# Azure imports\n",
    "from azure.identity import ClientSecretCredential\n",
    "\n",
    "# SDK imports\n",
    "from azure.agrifood.farming import FarmBeatsClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Farmbeats Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FarmBeats Client definition\n",
    "credential = ClientSecretCredential(\n",
    "    tenant_id=farmbeats_config['tenant_id'],\n",
    "    client_id=farmbeats_config['client_id'],\n",
    "    client_secret=farmbeats_config['client_secret'],\n",
    "    authority=farmbeats_config['authority']\n",
    ")\n",
    "\n",
    "credential_scopes = [farmbeats_config['default_scope']]\n",
    "\n",
    "fb_client = FarmBeatsClient(\n",
    "    endpoint=farmbeats_config['instance_url'],\n",
    "    credential=credential,\n",
    "    credential_scopes=credential_scopes,\n",
    "    logging_enable=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forecast EVI for new AOI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Satellie Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "farmer_id = \"contoso_farmer\"\n",
    "boundary_id = \"sample-boundary-32\" \n",
    "boundary_geometry = '[[-121.5283155441284,38.16172478418468],[-121.51544094085693,38.16172478418468],[-121.51544094085693,38.16791636919515],[-121.5283155441284,38.16791636919515],[-121.5283155441284,38.16172478418468]]'\n",
    "timezone = get_timezone(json.loads(boundary_geometry))\n",
    "end_dt = datetime.strptime(datetime.now(timezone).strftime(\"%Y-%m-%d\"), \"%Y-%m-%d\")\n",
    "start_dt = end_dt - timedelta(days=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Boundary and get satelite and weather (historical and forecast)\n",
    "get_sat_weather_data(fb_client, \n",
    "                farmer_id, \n",
    "                boundary_id,\n",
    "                json.loads(boundary_geometry), \n",
    "                start_dt, \n",
    "                end_dt)\n",
    "\n",
    "# get boundary object\n",
    "boundary = fb_client.boundaries.get(\n",
    "            farmer_id=farmer_id,\n",
    "            boundary_id=boundary_id\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boundary.as_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = CONSTANTS['root_dir']\n",
    "\n",
    "sat_links = SatelliteUtil(farmbeats_client = fb_client).download_and_get_sat_file_paths(farmer_id, [boundary], start_dt, end_dt, root_dir)\n",
    "\n",
    "# get last available data of satellite data\n",
    "end_dt_w = datetime.strptime(\n",
    "    sat_links.sceneDateTime.sort_values(ascending=False).values[0][:10], \"%Y-%m-%d\"\n",
    ")\n",
    "# calculate 30 days from last satellite available date\n",
    "start_dt_w = end_dt_w - timedelta(days=CONSTANTS[\"input_days\"] - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get weather data historical\n",
    "weather_list = fb_client.weather.list(\n",
    "            farmer_id=  boundary.farmer_id,\n",
    "            boundary_id= boundary.id,\n",
    "            start_date_time=start_dt_w,\n",
    "            end_date_time=end_dt,\n",
    "            extension_id=farmbeats_config['weather_provider_extension_id'],\n",
    "            weather_data_type= \"historical\", \n",
    "            granularity=\"daily\")\n",
    "weather_data = []\n",
    "for w_data in weather_list:\n",
    "    weather_data.append(w_data)\n",
    "w_df_hist = WeatherUtil.get_weather_data_df(weather_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get weather data forecast\n",
    "weather_list = fb_client.weather.list(\n",
    "            farmer_id=  boundary.farmer_id,\n",
    "            boundary_id= boundary.id,\n",
    "            start_date_time=end_dt,\n",
    "            end_date_time=end_dt + timedelta(10),\n",
    "            extension_id=farmbeats_config['weather_provider_extension_id'], \n",
    "            weather_data_type= \"forecast\", \n",
    "            granularity=\"daily\")\n",
    "\n",
    "weather_data = []\n",
    "for w_data in weather_list:\n",
    "    weather_data.append(w_data)\n",
    "w_df_forecast = WeatherUtil.get_weather_data_df(weather_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge weather data\n",
    "weather_df = pd.concat([w_df_hist, w_df_forecast], axis=0, ignore_index=True)\n",
    "\n",
    "with open(CONSTANTS[\"w_pkl\"], \"rb\") as f:\n",
    "    w_parms, weather_mean, weather_std = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare ARD for test boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ard = ard_preprocess(\n",
    "        sat_file_links=sat_links,\n",
    "        w_df=weather_df,\n",
    "        sat_res_x=1,\n",
    "        var_name=CONSTANTS[\"var_name\"],\n",
    "        interp_date_start=end_dt_w - timedelta(days=60),\n",
    "        interp_date_end=end_dt_w,\n",
    "        w_parms=w_parms,\n",
    "        input_days=CONSTANTS[\"input_days\"],\n",
    "        output_days=CONSTANTS[\"output_days\"],\n",
    "        ref_tm=start_dt_w.strftime(\"%d-%m-%Y\"),\n",
    "        w_mn=weather_mean,\n",
    "        w_sd=weather_std,\n",
    "    )\n",
    "\n",
    "frcst_st_dt  = end_dt_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raise exception if ARD is empty\n",
    "if ard.shape[0] == 0:\n",
    "    raise Exception(\"Analysis ready dataset is empty\")\n",
    "# raise exception if data spills into multiple rows\n",
    "if ard.query(\"grp1_ > 0\").shape[0] > 0:\n",
    "    raise Exception(\n",
    "        \"More than one record has been found for more than one pixel\"\n",
    "    )\n",
    "# warning if nans are in input data or data is out of bounds\n",
    "if (\n",
    "    ard.query(\"not nan_input_evi\").shape[0] > 0\n",
    "    or ard.query(\"not nan_input_w\").shape[0] > 0\n",
    "    or ard.query(\"not nan_output_w\").shape[0] > 0\n",
    "):\n",
    "    print(\"Warning: NaNs found in the input data\")\n",
    "if (\n",
    "    ard.query(\n",
    "        \"nan_input_evi and nan_input_w and nan_output_w and  not input_evi_le1\"\n",
    "    ).shape[0]\n",
    "    > 0\n",
    "):\n",
    "    print(\"Warning: input data outside range of (-1,1) found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read model and weather normalization stats\n",
    "model = tf.keras.models.load_model(CONSTANTS[\"model_trained\"], compile=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model prediction\n",
    "label = model.predict(\n",
    "    [\n",
    "        np.array(ard.input_evi.to_list()),\n",
    "        np.array(ard.input_weather.to_list()),\n",
    "        np.array(ard.forecast_weather.to_list()),\n",
    "    ]\n",
    ")\n",
    "label_names = [\n",
    "    (frcst_st_dt + timedelta(days=i + 1)).strftime(\"%Y-%m-%d\")\n",
    "    for i in range(CONSTANTS[\"output_days\"])\n",
    "]\n",
    "\n",
    "\n",
    "pred_df = pd.DataFrame(label[:, :, 0], columns=label_names).assign(\n",
    "    lat=ard.lat_.values, long=ard.long_.values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.dropna().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write Output to TIF files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import time\n",
    "from IPython import display\n",
    "from rasterio.plot import show\n",
    "import shutil\n",
    "\n",
    "ref_tif = sat_links.filePath.values[0]\n",
    "with rasterio.open(ref_tif) as src:\n",
    "    ras_meta = src.profile\n",
    "\n",
    "time_stamp = datetime.strptime(datetime.now().strftime(\"%d/%m/%y %H:%M:%S\"), \"%d/%m/%y %H:%M:%S\")\n",
    "output_dir = \"results/model_output_\"+str(time_stamp)+\"/\"\n",
    "try:\n",
    "    if os.path.exists(output_dir):\n",
    "        shutil.rmtree(output_dir)\n",
    "    os.mkdir(output_dir)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for coln in pred_df.columns[:-2]: # Skip last 2 columns: lattiude, longitude\n",
    "    try:\n",
    "        data_array = np.array(pred_df[coln]).reshape(src.shape)\n",
    "        with rasterio.open(os.path.join(output_dir, coln + '.tif'), 'w', **ras_meta) as dst:\n",
    "            dst.write(data_array, indexes=1)\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize NDVI Forecast Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for coln in pred_df.columns[:-2]: # Skip last 2 columns: lattiude, longitude\n",
    "    try:\n",
    "        src = rasterio.open(os.path.join(output_dir, coln + '.tif'))\n",
    "        show(src.read(), transform=src.transform, title=coln)\n",
    "        #show_hist(src)\n",
    "        display.clear_output(wait=True)\n",
    "        time.sleep(1)  \n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next Step \n",
    "please go to [4_deploy_azure.ipynb](./4_deploy_azure.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 3
 },
 "nbformat": 4,
 "nbformat_minor": 5
}